{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import models\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpyro.diagnostics import hpdi\n",
    "\n",
    "from hbmep.nn import functional as F\n",
    "from hbmep.model.utils import Site as site\n",
    "\n",
    "from hbmep.config import Config\n",
    "from hbmep.model.utils import Site as site\n",
    "from scipy import stats\n",
    "\n",
    "from models import NonHierarchicalBayesianModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "src = \"/home/andres/repos/rat-mapping-paper/reports/L_CIRC/inference.pkl\"\n",
    "\n",
    "with open(src, \"rb\") as f:\n",
    "    df, encoder_dict, model, posterior_samples, = pickle.load(f)\n",
    "\n",
    "\n",
    "# prediction_df = model.make_prediction_dataset(df=df, min_intensity=0., max_intensity=500.)\n",
    "# posterior_predictive = model.predict(\n",
    "#     df=prediction_df, posterior_samples=posterior_samples\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a (400, 8, 21, 6)\n",
      "b (400, 8, 21, 6)\n",
      "L (400, 8, 21, 6)\n",
      "â„“ (400, 8, 21, 6)\n",
      "H (400, 8, 21, 6)\n"
     ]
    }
   ],
   "source": [
    "# a = posterior_samples[site.a]\n",
    "# b = posterior_samples[site.b]\n",
    "# L = posterior_samples[site.L]\n",
    "# ell = posterior_samples[site.ell]\n",
    "# H = posterior_samples[site.H]\n",
    "\n",
    "# x = np.linspace(0, 500, 1000)\n",
    "\n",
    "named_params = [site.a, site.b, site.L, site.ell, site.H]\n",
    "params = [posterior_samples[param][:400, ...] for param in named_params]\n",
    "\n",
    "for named_param, param in zip(named_params, params):\n",
    "    print(named_param, param.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = os.path.join(\"/home/andres/repos/rat-mapping-paper/reports/L_CIRC/predictions.pkl\")\n",
    "\n",
    "with open(src, \"rb\") as f:\n",
    "    x, _, subjects, compound_positions, configurations, response, = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 400, 21, 6, 500)\n",
      "(8, 1, 1, 1, 500)\n",
      "\n",
      "(8, 21, 400, 6, 500)\n",
      "(8, 1, 1, 1, 500)\n"
     ]
    }
   ],
   "source": [
    "norm_y = []\n",
    "norm_x = []\n",
    "\n",
    "for subject_ind, subject in enumerate(subjects):\n",
    "    curr_params = [\n",
    "        param[:, subject_ind, :, :][:, :, :, None] for param in params\n",
    "    ]\n",
    "    constant = curr_params[0].mean() #do this for bvs\n",
    "\n",
    "    x_temp = np.linspace(0., 5 * constant, 500)\n",
    "    x_temp = x_temp[None, None, None, :]\n",
    "\n",
    "    temp_thresh = F.rectified_logistic(\n",
    "        x_temp,\n",
    "        *curr_params\n",
    "    )\n",
    "    norm_y.append(temp_thresh)\n",
    "    norm_x.append(x_temp)\n",
    "\n",
    "norm_y = np.array(norm_y)\n",
    "norm_x = np.array(norm_x)\n",
    "\n",
    "print(norm_y.shape)\n",
    "print(norm_x.shape)\n",
    "\n",
    "norm_y = np.swapaxes(norm_y, 1, 2)\n",
    "norm_x = np.swapaxes(norm_x, 1, 2)\n",
    "print()\n",
    "print(norm_y.shape)\n",
    "print(norm_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(subset):\n",
    "    y = norm_y[:, subset, ...]\n",
    "    x = norm_x[:, :, 0, 0, :]\n",
    "\n",
    "    y_max = ma.max(y, axis=(1, -1), keepdims=True) \n",
    "    y_max.shape\n",
    "\n",
    "    y = ma.where(y, y / y_max, 0.)\n",
    "    y.shape\n",
    "\n",
    "    p = ma.sum(y, axis=-2, keepdims=True)\n",
    "    p = ma.where(y, y / p, 0.)\n",
    "    p.shape\n",
    "\n",
    "    plogp = ma.where(p, p * ma.log(p), 0.)\n",
    "    plogp.shape\n",
    "\n",
    "    entropy = ma.where(\n",
    "        ma.any(p, axis=-2, keepdims=True),\n",
    "        (\n",
    "            1\n",
    "            + (ma.sum(plogp, axis=-2, keepdims=True) / np.log(plogp.shape[-2]))\n",
    "        ),\n",
    "        0.\n",
    "    )\n",
    "    entropy = entropy[..., 0, :]\n",
    "    entropy.shape\n",
    "\n",
    "    return entropy, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = [(i, cpos) for i, cpos in enumerate(compound_positions) if cpos.split(\"-\")[0] == \"\"]\n",
    "radii = [(i, cpos) for i, cpos in enumerate(compound_positions) if cpos.split(\"-\")[0] and cpos.split(\"-\")[1] == \"C6LC\"]\n",
    "diameters = [(i, cpos) for i, cpos in enumerate(compound_positions) if (i, cpos) not in vertices and (i, cpos) not in radii]\n",
    "\n",
    "vertices = [i for (i, cpos) in vertices]\n",
    "radii = [i for (i, cpos) in radii]\n",
    "diameters = [i for (i, cpos) in diameters]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 13, 16, 18]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_positions[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy, x = get_entropy(diameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = len(subjects), len(entropy[0,:,0,0])\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=nrows, ncols=ncols, constrained_layout=True, squeeze=False, figsize=(ncols * 5, nrows * 2)\n",
    ")\n",
    "\n",
    "if len(entropy[0,:,0,0]) == 4: \n",
    "    configuration = diameters\n",
    "elif len(entropy[0,:,0,0]) == 8:\n",
    "    configuration = vertices\n",
    "else:\n",
    "    configuration = radii\n",
    "    \n",
    "for subject_ind, subject in enumerate(subjects):\n",
    "    j = 0\n",
    "    for cpos_ind in range(len(entropy[0,:,0,0])):\n",
    "        cpos = compound_positions[configuration[cpos_ind]]\n",
    "        ax = axes[subject_ind, j]\n",
    "        samples = entropy[subject_ind, cpos_ind, :, :]\n",
    "        samples_mean = samples.mean(axis=0)\n",
    "        \n",
    "        samples_hdi = hpdi(samples, 0.95, axis=0)\n",
    "        x_temp = x[subject_ind, 0, ...].tolist()\n",
    "        \n",
    "        sns.lineplot(x=x_temp, y=samples_mean, ax=ax)\n",
    "        ax.fill_between(x_temp, samples_hdi[0, :], samples_hdi[1, :], color=\"C1\")\n",
    "        ax.set_title(f\"{subject}, {cpos}\")\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_list = []\n",
    "for subject_ind, subject in enumerate(subjects):\n",
    "\n",
    "    for cpos_ind in range(len(entropy[0,:,0,0])):\n",
    "        cpos = compound_positions[configuration[cpos_ind]]\n",
    "        x_temp = x[subject_ind, 0, ...].tolist()\n",
    "        \n",
    "        sample_integrals = entropy[subject_ind, cpos_ind, :, :]\n",
    "        sample_integrals_mean = sample_integrals.mean(axis=0)\n",
    "        \n",
    "        area = np.trapz(sample_integrals_mean, x_temp)\n",
    "        area_list.append((subject, cpos, area))\n",
    "\n",
    "filt_positions = list(set((a[1] for a in area_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = []\n",
    "means = []\n",
    "lab = []\n",
    "labels = []\n",
    "\n",
    "for pos_ind_one, p_one in enumerate(filt_positions):    \n",
    "    for pos_ind_two, p_two in enumerate(filt_positions):         \n",
    "        if pos_ind_one == pos_ind_two:\n",
    "            pvalues.append((0))\n",
    "            lab.append(p_one)\n",
    "            means.append(0)\n",
    "            labels.append(p_one)\n",
    "            continue\n",
    "        group_one = np.array(list(a[2] for a in area_list if a[1] == p_one))\n",
    "        group_two = np.array(list(a[2] for a in area_list if a[1] == p_two))\n",
    "        ttest = stats.ttest_rel(group_one, group_two, alternative='two-sided')\n",
    "        pvalues.append(ttest.pvalue)\n",
    "        ci = ttest.confidence_interval(.95)\n",
    "        # pvalues.append((p_one, p_two, f\"{stats.ttest_rel(group_one, group_two, alternative='two-sided')[1]}\"))\n",
    "        t = group_one - group_two\n",
    "        means.append(t.mean())\n",
    "        lab.append(f\"{t.mean():.3f}\\n({ci.low:.2f}, {ci.high:.2f})\\n{ttest.pvalue:.3f}\")\n",
    "\n",
    "pvalues = np.array(pvalues)\n",
    "pvalues = pvalues.reshape(4,4)\n",
    "\n",
    "means = np.array(means)\n",
    "means = means.reshape(4,4)\n",
    "\n",
    "lab = np.array(lab)\n",
    "lab = lab.reshape(4,4)\n",
    "# unique_pvalues = set(tuple(sorted(t)) for t in pvalues)\n",
    "\n",
    "mask = np.tril(np.ones_like(means), k=-1)\n",
    "# mask = np.tril(np.ones_like(mask), k=-1)\n",
    "plt.figure(figsize=(15, 5))\n",
    "ax =sns.heatmap(means, xticklabels= labels, annot = lab, yticklabels= labels, mask = mask, fmt = \"\", cbar = False,center = 0, cmap = \"coolwarm\")\n",
    "\n",
    "hatch_mask = pvalues > 0.1\n",
    "handles = []\n",
    "\n",
    "for i in range (pvalues.shape[0]):\n",
    "  for j in range(pvalues.shape[1]):\n",
    "      if hatch_mask[i, j]:\n",
    "        ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False, hatch='////', edgecolor='white'))\n",
    "handles.append(plt.Rectangle((0, 0), 0, 0, color='white', ec='black',\n",
    "                    hatch='', label=\"Significant\"))\n",
    "handles.append(plt.Rectangle((0, 0), 0, 0, color='white', ec='black',\n",
    "                    hatch='////', label=\"Not Significant\"))\n",
    "handles.append(plt.Rectangle((0, 0), 0, 0, color='blue', ec='black',\n",
    "                    hatch='', label=\"Row Element Lower Threshold\"))\n",
    "handles.append(plt.Rectangle((0, 0), 0, 0, color='Red', ec='black',\n",
    "                    hatch='', label=\"Row Element Higher Threshold\"))\n",
    "ax.legend(handles=handles, loc='lower left', bbox_to_anchor=(0, .1),\n",
    "          handlelength=2, handleheight=2, frameon=False)\n",
    "ax.tick_params(left= False,labelleft = False, bottom= False,labelbottom= False,right=True, top=True, labelright=True, labeltop=True, labelrotation=0)\n",
    "\n",
    "ax.yaxis.tick_right()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = [(i, cpos) for i, cpos in enumerate(compound_positions) if cpos.split(\"-\")[0] == \"\"]\n",
    "radii = [(i, cpos) for i, cpos in enumerate(compound_positions) if cpos.split(\"-\")[0] and cpos.split(\"-\")[1] == \"C6LC\"]\n",
    "diameters = [(i, cpos) for i, cpos in enumerate(compound_positions) if (i, cpos) not in vertices and (i, cpos) not in radii]\n",
    "\n",
    "vertices = [i for (i, cpos) in vertices]\n",
    "radii = [i for (i, cpos) in radii]\n",
    "diameters = [i for (i, cpos) in diameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_entropy_heatmap(config):   \n",
    "    global compound_positions \n",
    "    \n",
    "    func_entrop, x_val = get_entropy(config)\n",
    "    \n",
    "    area_list = []\n",
    "    \n",
    "    if len(func_entrop[0,:,0,0]) == 4: \n",
    "        configuration = diameters\n",
    "    elif len(func_entrop[0,:,0,0]) == 8:\n",
    "        configuration = radii\n",
    "    else:\n",
    "        configuration = vertices\n",
    "        \n",
    "    for subject_ind, subject in enumerate(subjects):\n",
    "\n",
    "        for cpos_ind in range(len(func_entrop[0,:,0,0])):\n",
    "            cpos = compound_positions[configuration[cpos_ind]]\n",
    "            x_temp = x_val[subject_ind, 0, ...].tolist()\n",
    "            \n",
    "            sample_integrals = func_entrop[subject_ind, cpos_ind, :, :]\n",
    "            sample_integrals_mean = sample_integrals.mean(axis=0)\n",
    "            \n",
    "            area = np.trapz(sample_integrals_mean, x_temp)\n",
    "            area_list.append((subject, cpos, area))\n",
    "\n",
    "    filt_positions = list(set((a[1] for a in area_list)))\n",
    "\n",
    "    pvalues = []\n",
    "    means = []\n",
    "    annot = []\n",
    "    labels = []\n",
    "    ind_mean_values = []\n",
    "\n",
    "    for pos_ind_one, p_one in enumerate(filt_positions):    \n",
    "        for pos_ind_two, p_two in enumerate(filt_positions):         \n",
    "            if pos_ind_one == pos_ind_two:\n",
    "                pvalues.append((0))\n",
    "                annot.append(p_one)\n",
    "                means.append(0)\n",
    "                labels.append(p_one)\n",
    "                indiv = np.array(list(a[2] for a in area_list if a[1] == p_one))\n",
    "                ind_mean_values.append(indiv.mean())\n",
    "                continue\n",
    "            group_one = np.array(list(a[2] for a in area_list if a[1] == p_one))\n",
    "            group_two = np.array(list(a[2] for a in area_list if a[1] == p_two))\n",
    "\n",
    "            ttest = stats.ttest_rel(group_one, group_two, alternative='two-sided')\n",
    "            pvalues.append(ttest.pvalue)\n",
    "            ci = ttest.confidence_interval(.95)\n",
    "            t = group_one - group_two\n",
    "            means.append(t.mean())\n",
    "            annot.append(f\"{t.mean():.3f}\\n({ci.low:.2f}, {ci.high:.2f})\\n{ttest.pvalue:.3f}\")\n",
    "\n",
    "    pvalues = np.array(pvalues)\n",
    "    ret_pvalues = pvalues\n",
    "    pvalues = pvalues.reshape(len(func_entrop[0,:,0,0]),len(func_entrop[0,:,0,0]))\n",
    "\n",
    "    means = np.array(means)\n",
    "    means = means.reshape(len(func_entrop[0,:,0,0]),len(func_entrop[0,:,0,0]))\n",
    "\n",
    "    annot = np.array(annot)\n",
    "    annot = annot.reshape(len(func_entrop[0,:,0,0]),len(func_entrop[0,:,0,0]))\n",
    "\n",
    "    mask = np.tril(np.ones_like(means), k=-1)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    ax =sns.heatmap(means, xticklabels= labels, annot = annot, yticklabels= labels, mask = mask, fmt = \"\", cbar = False,center = 0, cmap = \"coolwarm\")\n",
    "\n",
    "    hatch_mask = pvalues > 0.1\n",
    "    handles = []\n",
    "\n",
    "    for i in range (pvalues.shape[0]):\n",
    "        for j in range(pvalues.shape[1]):\n",
    "            if hatch_mask[i, j]:\n",
    "                ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False, hatch='////', edgecolor='white'))\n",
    "    handles.append(plt.Rectangle((0, 0), 0, 0, color='white', ec='black',\n",
    "                        hatch='', label=\"Significant\"))\n",
    "    handles.append(plt.Rectangle((0, 0), 0, 0, color='white', ec='black',\n",
    "                        hatch='////', label=\"Not Significant\"))\n",
    "    handles.append(plt.Rectangle((0, 0), 0, 0, color='blue', ec='black',\n",
    "                        hatch='', label=\"Row Element Lower Threshold\"))\n",
    "    handles.append(plt.Rectangle((0, 0), 0, 0, color='Red', ec='black',\n",
    "                        hatch='', label=\"Row Element Higher Threshold\"))\n",
    "    ax.legend(handles=handles, loc='lower left', bbox_to_anchor=(0, .1),\n",
    "            handlelength=2, handleheight=2, frameon=False)\n",
    "    ax.tick_params(left= False,labelleft = False, bottom= False,labelbottom= False,right=True, top=True, labelright=True, labeltop=True, labelrotation=0)\n",
    "\n",
    "    ax.yaxis.tick_right()\n",
    "    \n",
    "    if len(config) == 4:\n",
    "        plt.title(\"Diameters\")\n",
    "        \n",
    "    elif len(config) == 8:\n",
    "        plt.title(\"Radii\")\n",
    "    else: \n",
    "        plt.title(\"Vertices\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return ind_mean_values, labels, ret_pvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_mean_values, labels, pvalues = graph_entropy_heatmap(diameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circ_values = ind_mean_values + ind_mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circ_labels = labels + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_list = []\n",
    "for subject_ind, subject in enumerate(subjects):\n",
    "\n",
    "    for cpos_ind in range(len(entropy[0,:,0,0])):\n",
    "        cpos = compound_positions[configuration[cpos_ind]]\n",
    "        x_temp = x[subject_ind, 0, ...].tolist()\n",
    "        \n",
    "        sample_integrals = entropy[subject_ind, cpos_ind, :, :]\n",
    "        sample_integrals_mean = sample_integrals.mean(axis=0)\n",
    "        \n",
    "        area = np.trapz(sample_integrals_mean, x_temp)\n",
    "        area_list.append((subject, cpos, area))\n",
    "\n",
    "filt_positions = list(set((a[1] for a in area_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = []\n",
    "means = []\n",
    "lab = []\n",
    "labels = []\n",
    "graph_vals = []\n",
    "\n",
    "for pos_ind_one, p_one in enumerate(filt_positions):    \n",
    "    for pos_ind_two, p_two in enumerate(filt_positions):         \n",
    "        if pos_ind_one == pos_ind_two:\n",
    "            pvalues.append(0)\n",
    "            means.append(0)\n",
    "            labels.append(p_one)\n",
    "            graph_vals.append((np.array(list(a[2] for a in area_list if a[1] == p_one)).mean()))\n",
    "            continue\n",
    "        group_one = np.array(list(a[2] for a in area_list if a[1] == p_one))\n",
    "        group_two = np.array(list(a[2] for a in area_list if a[1] == p_two))\n",
    "        ttest = stats.ttest_rel(group_one, group_two, alternative='two-sided')\n",
    "        pvalues.append(ttest.pvalue)\n",
    "        ci = ttest.confidence_interval(.95)\n",
    "        # pvalues.append((p_one, p_two, f\"{stats.ttest_rel(group_one, group_two, alternative='two-sided')[1]}\"))\n",
    "        t = group_one - group_two\n",
    "        means.append(t.mean())\n",
    "        labels.append((p_one, p_two))\n",
    "\n",
    "pvalues = np.array(pvalues)\n",
    "# pvalues = pvalues.reshape(4,4)\n",
    "\n",
    "means = np.array(means)\n",
    "# means = means.reshape(4,4)\n",
    "\n",
    "# lab = lab.reshape(4,4)\n",
    "# unique_pvalues = set(tuple(sorted(t)) for t in pvalues)\n",
    "\n",
    "# mask = np.tril(np.ones_like(means), k=-1)\n",
    "# # mask = np.tril(np.ones_like(mask), k=-1)\n",
    "# plt.figure(figsize=(15, 5))\n",
    "# ax =sns.heatmap(means, xticklabels= labels, annot = lab, yticklabels= labels, mask = mask, fmt = \"\", cbar = False,center = 0, cmap = \"coolwarm\")\n",
    "\n",
    "# hatch_mask = pvalues > 0.1\n",
    "# handles = []\n",
    "\n",
    "# for i in range (pvalues.shape[0]):\n",
    "#   for j in range(pvalues.shape[1]):\n",
    "#       if hatch_mask[i, j]:\n",
    "#         ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False, hatch='////', edgecolor='white'))\n",
    "# handles.append(plt.Rectangle((0, 0), 0, 0, color='white', ec='black',\n",
    "#                     hatch='', label=\"Significant\"))\n",
    "# handles.append(plt.Rectangle((0, 0), 0, 0, color='white', ec='black',\n",
    "#                     hatch='////', label=\"Not Significant\"))\n",
    "# handles.append(plt.Rectangle((0, 0), 0, 0, color='blue', ec='black',\n",
    "#                     hatch='', label=\"Row Element Lower Threshold\"))\n",
    "# handles.append(plt.Rectangle((0, 0), 0, 0, color='Red', ec='black',\n",
    "#                     hatch='', label=\"Row Element Higher Threshold\"))\n",
    "# ax.legend(handles=handles, loc='lower left', bbox_to_anchor=(0, .1),\n",
    "#           handlelength=2, handleheight=2, frameon=False)\n",
    "# ax.tick_params(left= False,labelleft = False, bottom= False,labelbottom= False,right=True, top=True, labelright=True, labeltop=True, labelrotation=0)\n",
    "\n",
    "# ax.yaxis.tick_right()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_angles[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph results with bubble plot\n",
    "bubble_angles = [] \n",
    "for a in (area_list):\n",
    "    if a[1] == 'C6LSE-C6LNW':\n",
    "        bubble_angles.append(135)\n",
    "    elif a[1] == 'C6LE-C6LW':\n",
    "        bubble_angles.append(90)\n",
    "    elif a[1] == 'C6LS-C6LN':\n",
    "        bubble_angles.append(180)\n",
    "    elif a[1] == 'C6LNE-C6LSW':\n",
    "        bubble_angles.append(45)\n",
    "\n",
    "\n",
    "color_map = {'C6LSE-C6LNW':'blue', 'C6LE-C6LW':'red', 'C6LS-C6LN':'green', 'C6LNE-C6LSW':'orange'}\n",
    "\n",
    "bubble_rads = np.radians(bubble_angles)\n",
    "\n",
    "bubble_sizes = 10\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "bubble_label = []\n",
    "for i, a in enumerate(area_list):\n",
    "    # ax.text(bubble_rads[i], .5, label, horizontalalignment='center', verticalalignment='center')\n",
    "    ax.scatter(bubble_rads[i], 10,  #x = angle, y = radius\n",
    "                s=area_list[i][2]*10,alpha=0.1, color= color_map[a[1]],edgecolors='black')\n",
    "\n",
    "plt.legend(color_map.keys(), loc='upper left')\n",
    "plt.xticks(bubble_rads[0:4], list((a[1] for a in area_list[0:4])))  \n",
    "ax.set_yticklabels([])\n",
    "ax.yaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'curve_parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcurve_parameters\u001b[49m(named_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'curve_parameters' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_together_bubble_plot(ind):\n",
    "\n",
    "    global compound_positions\n",
    "    a = curve_parameters(named_param='a')\n",
    "    a = a / ma.median(a, axis=(1, 2, 3), keepdims=True)\n",
    "\n",
    "    #col = model._get_colors(model.n_response)[musc]\n",
    "    \n",
    "    angles_key = ['nan', 90, 0, 45, 315, 180, 135, 225, 270, 90, 90, 0, 45, 45, 315, 180, 180, 135, 135, 225, 270]\n",
    "    color_dict = {\n",
    "        '-C6LC': '#1f77b4',\n",
    "        '-C6LE': '#ff7f0e',\n",
    "        '-C6LN': '#2ca02c',\n",
    "        '-C6LNE': '#d62728',\n",
    "        '-C6LNW': '#9467bd',\n",
    "        '-C6LS': '#8c564b',\n",
    "        '-C6LSE': '#e377c2',\n",
    "        '-C6LSW': '#7f7f7f',\n",
    "        '-C6LW': '#bcbd22',\n",
    "        'C6LE-C6LC': '#17becf',\n",
    "        'C6LE-C6LW': '#aec7e8',\n",
    "        'C6LN-C6LC': '#ffbb78',\n",
    "        'C6LNE-C6LC': '#98df8a',\n",
    "        'C6LNE-C6LSW': '#ff9896',\n",
    "        'C6LNW-C6LC': '#c5b0d5',\n",
    "        'C6LS-C6LC': '#c49c94',\n",
    "        'C6LS-C6LN': '#f7b6d2',\n",
    "        'C6LSE-C6LC': '#c7c7c7',\n",
    "        'C6LSE-C6LNW': '#dbdb8d',\n",
    "        'C6LSW-C6LC': '#9edae5',\n",
    "        'C6LW-C6LC': '#fdfd96'\n",
    "    }\n",
    "    conf_ind = ind\n",
    "    mean_list = []\n",
    "\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(30, 30), subplot_kw=dict(polar=True))\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    significant_pairs = []\n",
    "    \n",
    "    for musc in range(model.n_response):\n",
    "        mean_list = []\n",
    "        arr_responses = a[:,conf_ind,:,musc,:]\n",
    "\n",
    "        for sub_ind, s in enumerate(subjects):\n",
    "            for c_ind, c in enumerate(arr_responses[0,:,0]):\n",
    "                if arr_responses.mask[sub_ind,c_ind,:].all():\n",
    "                    continue\n",
    "                \n",
    "                mean_list.append((subjects[sub_ind], compound_positions[c_ind], arr_responses[sub_ind,c_ind,:].mean()))\n",
    "\n",
    "        filt_positions = list(set((z[1] for z in mean_list)))\n",
    "\n",
    "        bubble_rads = [] \n",
    "        \n",
    "        for z in (mean_list):\n",
    "            if z[1] == '-C6LC':\n",
    "                bubble_rads.append(0)\n",
    "            else:\n",
    "                bubble_rads.append(np.radians(angles_key[compound_positions.index(z[1])]))\n",
    "            \n",
    "        \n",
    "        ax[musc].set_theta_offset(np.pi / 2)\n",
    "        ax[musc].set_theta_direction(-1)\n",
    "        \n",
    "        min_mean = min((z[2] for z in mean_list))    \n",
    "        \n",
    "        # cols = cols.reshape(-1)\n",
    "        for i, z in enumerate(mean_list):\n",
    "            # ax.text(bubble_rads[i], .5, label, horizontalalignment='center', verticalalignment='center')\n",
    "            if z[1] == '-C6LC':\n",
    "                eff_temp = (mean_list[i][2]-min_mean)\n",
    "                ax[musc].scatter(0, 0,  #x = angle, y = radius\n",
    "                        s=(eff_temp)*5000, alpha=0.1, color = model._get_colors(model.n_response)[musc], edgecolors='black')\n",
    "            else:\n",
    "                eff_temp = ((mean_list[i][2]-min_mean))\n",
    "                if eff_temp == 0:\n",
    "                    ax[musc].scatter(bubble_rads[i], 10,  #x = angle, y = radius\n",
    "                            s=(min_mean*5000), alpha=0.1, color = model._get_colors(model.n_response)[musc], edgecolors='black')\n",
    "                else:\n",
    "                    ax[musc].scatter(bubble_rads[i], 10,  #x = angle, y = radius\n",
    "                                s=(eff_temp*5000), alpha=0.1, color = model._get_colors(model.n_response)[musc], edgecolors='black')\n",
    "\n",
    "        stop = len(filt_positions)\n",
    "        ax[musc].set_xticks(bubble_rads[0:stop], list((z[1] for z in mean_list[0:stop])))  \n",
    "        ax[musc].set_yticklabels([])\n",
    "        ax[musc].yaxis.set_visible(False)\n",
    "        if ind == 0:\n",
    "            ax[musc].text(0, 0, 'C6LC', horizontalalignment='center', verticalalignment='center')\n",
    "        ax[musc].set_title(f\"Mean Threshold for each position, individual rat, muscle: {model.response[musc]} \\n Smaller = more effective\" )\n",
    "    \n",
    "\n",
    "    fig.show()\n",
    "    # ax[musc].set_title(f\"Mean Threshold for each position, individual rat, muscle: {model.response(musc)} \\n Smaller = more effective\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
