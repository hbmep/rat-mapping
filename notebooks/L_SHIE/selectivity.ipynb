{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import models\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpyro.diagnostics import hpdi\n",
    "\n",
    "from hbmep.nn import functional as F\n",
    "from hbmep.model.utils import Site as site\n",
    "\n",
    "from hbmep.config import Config\n",
    "from hbmep.model.utils import Site as site\n",
    "from scipy import stats\n",
    "\n",
    "from models import NonHierarchicalBayesianModel\n",
    "\n",
    "USER = os.environ[\"USER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = f\"/home/andres/repos/rat-mapping-paper/reports/non-hierarchical/L_SHIE/non_hierarchical_bayesian_model/inference.pkl\"\n",
    "with open(src, \"rb\") as f:\n",
    "    (\n",
    "        df,\n",
    "        encoder_dict,\n",
    "        model,\n",
    "        posterior_samples,\n",
    "    ) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20-0-80-25', '50-0-50-100'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_dict['compound_charge_params'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a (4000, 8, 4, 2, 6)\n",
      "b (4000, 8, 4, 2, 6)\n",
      "L (4000, 8, 4, 2, 6)\n",
      "â„“ (4000, 8, 4, 2, 6)\n",
      "H (4000, 8, 4, 2, 6)\n"
     ]
    }
   ],
   "source": [
    "a = posterior_samples[site.a]\n",
    "b = posterior_samples[site.b]\n",
    "L = posterior_samples[site.L]\n",
    "ell = posterior_samples[site.ell]\n",
    "H = posterior_samples[site.H]\n",
    "\n",
    "x = np.linspace(0, 500, 1000)\n",
    "\n",
    "named_params = [site.a, site.b, site.L, site.ell, site.H]\n",
    "params = [posterior_samples[param][ ...] for param in named_params]\n",
    "\n",
    "for named_param, param in zip(named_params, params):\n",
    "    \n",
    "    print(named_param, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = df['participant'].unique()\n",
    "subjects = sorted(encoder_dict['participant'].inverse_transform(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions =df['compound_position'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-C6LC', 'C6LC-', 'C6LC-C6LX', 'C6LX-C6LC']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(encoder_dict['compound_position'].inverse_transform(positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_y = []\n",
    "norm_x = []\n",
    "\n",
    "for subject_ind, subject in enumerate(subjects):\n",
    "    curr_params = [\n",
    "        param[:, subject_ind, ...][..., None] for param in params\n",
    "    ]\n",
    "    constant = np.nanmedian(np.nanmean(curr_params[0], axis=0))\n",
    "\n",
    "    x_temp = np.linspace(0., 5 * constant, 500)\n",
    "    x_temp = x_temp[None, None, None, None, :]\n",
    "\n",
    "    temp_thresh = F.rectified_logistic(\n",
    "        x_temp,\n",
    "        *curr_params\n",
    "    )\n",
    "    temp_thresh = temp_thresh - curr_params[2]\n",
    "    norm_y.append(temp_thresh)\n",
    "    norm_x.append(x_temp)\n",
    "\n",
    "norm_y = np.array(norm_y)\n",
    "norm_x = np.array(norm_x)\n",
    "\n",
    "# print(norm_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4000, 4, 2, 6, 500)\n"
     ]
    }
   ],
   "source": [
    "print(norm_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = norm_y\n",
    "arr = ma.masked_invalid(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4000, 6, 500)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[...,1,1,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(charge):\n",
    "    y = arr[...,charge,0,:,:]\n",
    "    x = norm_x\n",
    "\n",
    "    y_max = ma.max(y, axis=(2,-1), keepdims=True) \n",
    "\n",
    "    y = ma.where(y, y / y_max, 0.)\n",
    "\n",
    "    p = ma.sum(y, axis=-2, keepdims=True)\n",
    "    p = ma.where(y, y / p, 0.)\n",
    "\n",
    "    plogp = ma.where(p, p * ma.log(p), 0.)\n",
    "\n",
    "    entropy = ma.where(\n",
    "        ma.any(p, axis=-2, keepdims=True),\n",
    "        (\n",
    "            1\n",
    "            + (ma.sum(plogp, axis=-2, keepdims=True) / np.log(plogp.shape[-2]))\n",
    "        ),\n",
    "        0.\n",
    "    )\n",
    "    entropy = entropy[..., 0, :]\n",
    "    entropy.shape\n",
    "\n",
    "    return entropy, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_position = encoder_dict[model.features[1]].inverse_transform(sorted(df['compound_position'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-C6LC', 'C6LC-', 'C6LC-C6LX', 'C6LX-C6LC'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compound_position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashc_entropy, dashc_x = get_entropy(0)\n",
    "cdash_entropy, cdash_x = get_entropy(1)\n",
    "c_x_entropy, c_x_x = get_entropy(2)\n",
    "x_c_entropy, x_c_x = get_entropy(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1, 1, 1, 1, 500)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_c_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4000, 500)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_x_entropy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC(entropy, x):\n",
    "    area_list = []\n",
    "    for subject_ind, subject in enumerate(subjects):\n",
    "        x_temp = x[subject_ind, 0,0,0, ...]\n",
    "        sample_integrals = entropy[subject_ind, ...]\n",
    "        area = np.trapz(sample_integrals, x_temp)\n",
    "        area_list.append(area)\n",
    "\n",
    "    area_list = np.array(area_list)\n",
    "    area_list = area_list.reshape(len(subjects), *area_list.shape[1:])\n",
    "    area_list = ma.masked_values(area_list, 0)\n",
    "    area_list_mean = ma.mean(area_list, axis=(-1))\n",
    "    \n",
    "    return area_list_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashc = AUC(dashc_entropy, dashc_x)\n",
    "cdash = AUC(cdash_entropy, cdash_x)\n",
    "c_x = AUC(c_x_entropy, c_x_x)\n",
    "x_c = AUC(x_c_entropy, x_c_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = f\"/home/andres/repos/rat-mapping-paper/notebooks/L_SHIE/selectivity_means.pkl\"\n",
    "\n",
    "with open(src, \"wb\") as f:\n",
    "    pickle.dump([dashc , cdash, c_x, x_c], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
